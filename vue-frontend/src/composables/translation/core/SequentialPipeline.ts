/**
 * é¡ºåºç¿»è¯‘ç®¡çº¿ - åŸå­æ­¥éª¤ç‰ˆæœ¬
 * 
 * è®¾è®¡ç†å¿µï¼šä¸å¹¶è¡Œç®¡çº¿å®Œå…¨ä¸€è‡´çš„åŸå­æ­¥éª¤
 * 
 * 7ä¸ªåŸå­æ­¥éª¤ï¼š
 * 1. detection - æ°”æ³¡æ£€æµ‹
 * 2. ocr - æ–‡å­—è¯†åˆ«
 * 3. color - é¢œè‰²æå–
 * 4. translate - æ™®é€šç¿»è¯‘
 * 5. aiTranslate - AIç¿»è¯‘ï¼ˆé«˜è´¨é‡ç¿»è¯‘å’Œæ ¡å¯¹å…±ç”¨ï¼‰
 * 6. inpaint - èƒŒæ™¯ä¿®å¤
 * 7. render - æ¸²æŸ“è¯‘æ–‡
 */

import { ref, computed } from 'vue'
import { useImageStore } from '@/stores/imageStore'
import { useBubbleStore } from '@/stores/bubbleStore'
import { useSettingsStore } from '@/stores/settingsStore'
import { useValidation } from '../../useValidation'
import { useToast } from '@/utils/toast'
import { createRateLimiter, type RateLimiter } from '@/utils/rateLimiter'
import { createProgressManager } from './progressManager'
import type {
    PipelineConfig,
    PipelineResult,
    SavedTextStyles,
    TranslationMode
} from './types'
import type { ImageData as AppImageData } from '@/types/image'
import type { BubbleState, BubbleCoords } from '@/types/bubble'

// åˆ†æ­¥ API
import {
    parallelDetect,
    parallelOcr,
    parallelColor,
    parallelTranslate,
    parallelInpaint,
    parallelRender,
    type ParallelDetectResponse,
    type ParallelOcrResponse,
    type ParallelColorResponse,
    type ParallelTranslateResponse,
    type ParallelInpaintResponse,
    type ParallelRenderResponse
} from '@/api/parallelTranslate'
import { hqTranslateBatch } from '@/api/translate'

// ============================================================
// åŸå­æ­¥éª¤ç±»å‹
// ============================================================

export type AtomicStepType =
    | 'detection'     // æ°”æ³¡æ£€æµ‹
    | 'ocr'           // æ–‡å­—è¯†åˆ«
    | 'color'         // é¢œè‰²æå–
    | 'translate'     // æ™®é€šç¿»è¯‘
    | 'aiTranslate'   // AIç¿»è¯‘ï¼ˆé«˜è´¨é‡ç¿»è¯‘ & æ ¡å¯¹å…±ç”¨ï¼‰
    | 'inpaint'       // èƒŒæ™¯ä¿®å¤
    | 'render'        // æ¸²æŸ“

/**
 * æ­¥éª¤é“¾é…ç½®
 */
export const STEP_CHAIN_CONFIGS: Record<TranslationMode, AtomicStepType[]> = {
    standard: ['detection', 'ocr', 'color', 'translate', 'inpaint', 'render'],
    hq: ['detection', 'ocr', 'color', 'aiTranslate', 'inpaint', 'render'],
    proofread: ['aiTranslate', 'render'],
    removeText: ['detection', 'inpaint', 'render']
}

/** æ­¥éª¤æ˜¾ç¤ºåç§° */
const STEP_LABELS: Record<AtomicStepType, string> = {
    detection: 'æ°”æ³¡æ£€æµ‹',
    ocr: 'æ–‡å­—è¯†åˆ«',
    color: 'é¢œè‰²æå–',
    translate: 'ç¿»è¯‘',
    aiTranslate: 'AIç¿»è¯‘',
    inpaint: 'èƒŒæ™¯ä¿®å¤',
    render: 'æ¸²æŸ“'
}

// ============================================================
// ä»»åŠ¡çŠ¶æ€
// ============================================================

interface TaskState {
    imageIndex: number
    image: AppImageData

    // æ£€æµ‹ç»“æœ
    bubbleCoords: BubbleCoords[]
    bubbleAngles: number[]
    bubblePolygons: number[][][]
    autoDirections: string[]
    rawMask?: string
    textlinesPerBubble: any[]

    // OCRç»“æœ
    originalTexts: string[]

    // é¢œè‰²ç»“æœ
    colors: Array<{
        textColor: string
        bgColor: string
        autoFgColor?: [number, number, number] | null
        autoBgColor?: [number, number, number] | null
    }>

    // ç¿»è¯‘ç»“æœ
    translatedTexts: string[]
    textboxTexts: string[]

    // ä¿®å¤ç»“æœ
    cleanImage?: string

    // æ¸²æŸ“ç»“æœ
    finalImage?: string
    bubbleStates?: BubbleState[]
}

// ============================================================
// é¡ºåºç®¡çº¿ Composable
// ============================================================

export function useSequentialPipeline() {
    const imageStore = useImageStore()
    const bubbleStore = useBubbleStore()
    const settingsStore = useSettingsStore()
    const validation = useValidation()
    const toast = useToast()

    const { progress, reporter } = createProgressManager()
    const isExecuting = ref(false)
    const rateLimiter = ref<RateLimiter | null>(null)
    let savedTextStyles: SavedTextStyles | null = null
    let currentMode: TranslationMode = 'standard'

    const isTranslating = computed(() => isExecuting.value || imageStore.isBatchTranslationInProgress)
    const progressPercent = computed(() => progress.value.percentage || 0)

    // ============================================================
    // å·¥å…·å‡½æ•°
    // ============================================================

    function initRateLimiter(): void {
        const rpm = settingsStore.settings.translation.rpmLimit
        if (!rateLimiter.value) {
            rateLimiter.value = createRateLimiter(rpm)
        } else {
            rateLimiter.value.setRpm(rpm)
        }
    }

    function validateConfig(config: PipelineConfig): boolean {
        const validationType = config.mode === 'hq' ? 'hq'
            : config.mode === 'proofread' ? 'proofread'
                : config.mode === 'removeText' ? 'ocr'
                    : 'normal'
        return validation.validateBeforeTranslation(validationType)
    }

    function saveCurrentStyles(): void {
        const { textStyle } = settingsStore.settings
        const layoutDirectionValue = textStyle.layoutDirection
        savedTextStyles = {
            fontFamily: textStyle.fontFamily,
            fontSize: textStyle.fontSize,
            autoFontSize: textStyle.autoFontSize,
            autoTextDirection: layoutDirectionValue === 'auto',
            textDirection: layoutDirectionValue === 'auto' ? 'vertical' : layoutDirectionValue,
            fillColor: textStyle.fillColor,
            textColor: textStyle.textColor,
            rotationAngle: 0,
            strokeEnabled: textStyle.strokeEnabled,
            strokeColor: textStyle.strokeColor,
            strokeWidth: textStyle.strokeWidth
        }
    }

    function extractBase64(dataUrl: string): string {
        if (dataUrl.includes('base64,')) {
            return dataUrl.split('base64,')[1] || ''
        }
        return dataUrl
    }

    function getImagesToProcess(config: PipelineConfig): { image: AppImageData; index: number }[] {
        const images = imageStore.images
        if (config.scope === 'current') {
            const currentImage = imageStore.currentImage
            return currentImage ? [{ image: currentImage, index: imageStore.currentImageIndex }] : []
        }
        if (config.scope === 'failed') {
            return imageStore.getFailedImageIndices()
                .map(index => ({ image: images[index]!, index }))
                .filter(item => item.image !== undefined)
        }
        return images.map((image, index) => ({ image, index }))
    }

    // ============================================================
    // åŸå­æ­¥éª¤æ‰§è¡Œå™¨
    // ============================================================

    async function executeDetection(task: TaskState): Promise<void> {
        const settings = settingsStore.settings
        const base64 = extractBase64(task.image.originalDataURL)

        const response: ParallelDetectResponse = await parallelDetect({
            image: base64,
            detector_type: settings.textDetector,
            box_expand_ratio: settings.boxExpand.ratio,
            box_expand_top: settings.boxExpand.top,
            box_expand_bottom: settings.boxExpand.bottom,
            box_expand_left: settings.boxExpand.left,
            box_expand_right: settings.boxExpand.right
        })

        if (!response.success) {
            throw new Error(response.error || 'æ£€æµ‹å¤±è´¥')
        }

        task.bubbleCoords = (response.bubble_coords || []) as BubbleCoords[]
        task.bubbleAngles = response.bubble_angles || []
        task.bubblePolygons = response.bubble_polygons || []
        task.autoDirections = response.auto_directions || []
        task.rawMask = response.raw_mask
        task.textlinesPerBubble = response.textlines_per_bubble || []
    }

    async function executeOcr(task: TaskState): Promise<void> {
        if (task.bubbleCoords.length === 0) {
            task.originalTexts = []
            return
        }

        const settings = settingsStore.settings
        const base64 = extractBase64(task.image.originalDataURL)

        const response: ParallelOcrResponse = await parallelOcr({
            image: base64,
            bubble_coords: task.bubbleCoords,
            source_language: settings.sourceLanguage,
            ocr_engine: settings.ocrEngine,
            baidu_api_key: settings.baiduOcr?.apiKey,
            baidu_secret_key: settings.baiduOcr?.secretKey,
            baidu_version: settings.baiduOcr?.version,
            baidu_ocr_language: settings.baiduOcr?.sourceLanguage,
            ai_vision_provider: settings.aiVisionOcr?.provider,
            ai_vision_api_key: settings.aiVisionOcr?.apiKey,
            ai_vision_model_name: settings.aiVisionOcr?.modelName,
            ai_vision_ocr_prompt: settings.aiVisionOcr?.prompt,
            custom_ai_vision_base_url: settings.aiVisionOcr?.customBaseUrl,
            textlines_per_bubble: task.textlinesPerBubble
        })

        if (!response.success) {
            throw new Error(response.error || 'OCRå¤±è´¥')
        }

        task.originalTexts = response.original_texts || []
    }

    async function executeColor(task: TaskState): Promise<void> {
        if (task.bubbleCoords.length === 0) {
            task.colors = []
            return
        }

        const base64 = extractBase64(task.image.originalDataURL)

        const response: ParallelColorResponse = await parallelColor({
            image: base64,
            bubble_coords: task.bubbleCoords,
            textlines_per_bubble: task.textlinesPerBubble
        })

        if (!response.success) {
            throw new Error(response.error || 'é¢œè‰²æå–å¤±è´¥')
        }

        task.colors = response.colors || []
    }

    async function executeTranslate(task: TaskState): Promise<void> {
        if (task.originalTexts.length === 0) {
            task.translatedTexts = []
            task.textboxTexts = []
            return
        }

        const settings = settingsStore.settings

        const response: ParallelTranslateResponse = await parallelTranslate({
            original_texts: task.originalTexts,
            target_language: settings.targetLanguage,
            source_language: settings.sourceLanguage,
            model_provider: settings.translation.provider,
            model_name: settings.translation.modelName,
            api_key: settings.translation.apiKey,
            custom_base_url: settings.translation.customBaseUrl,
            prompt_content: settings.translatePrompt,
            textbox_prompt_content: settings.textboxPrompt,
            use_textbox_prompt: settings.useTextboxPrompt,
            rpm_limit: settings.translation.rpmLimit,
            max_retries: settings.translation.maxRetries,
            use_json_format: settings.translation.isJsonMode
        })

        if (!response.success) {
            throw new Error(response.error || 'ç¿»è¯‘å¤±è´¥')
        }

        task.translatedTexts = response.translated_texts || []
        task.textboxTexts = response.textbox_texts || []
    }

    /**
     * AIç¿»è¯‘æ­¥éª¤ï¼ˆé«˜è´¨é‡ç¿»è¯‘ & æ ¡å¯¹å…±ç”¨ï¼‰
     * æ ¹æ® currentMode å†³å®šä½¿ç”¨å“ªç§é…ç½®
     */
    async function executeAiTranslate(tasks: TaskState[]): Promise<void> {
        const settings = settingsStore.settings
        const isProofread = currentMode === 'proofread'

        // æ”¶é›† JSON æ•°æ®
        const jsonData = tasks.map(t => {
            if (isProofread) {
                // æ ¡å¯¹æ¨¡å¼ï¼šä½¿ç”¨å·²æœ‰è¯‘æ–‡
                return {
                    imageIndex: t.imageIndex,
                    bubbles: (t.image.bubbleStates || []).map((state, idx) => ({
                        bubbleIndex: idx,
                        original: state.originalText || '',
                        translated: settings.useTextboxPrompt
                            ? (state.textboxText || state.translatedText || '')
                            : (state.translatedText || ''),
                        // ã€ç®€åŒ–è®¾è®¡ã€‘ç›´æ¥ä½¿ç”¨ textDirectionï¼Œå®ƒå·²ç»æ˜¯å…·ä½“æ–¹å‘å€¼
                        textDirection: (state.textDirection === 'vertical' || state.textDirection === 'horizontal')
                            ? state.textDirection
                            : (state.autoTextDirection === 'vertical' || state.autoTextDirection === 'horizontal')
                                ? state.autoTextDirection
                                : 'vertical'
                    }))
                }
            } else {
                // é«˜è´¨é‡ç¿»è¯‘ï¼šä½¿ç”¨ OCR ç»“æœ
                return {
                    imageIndex: t.imageIndex,
                    bubbles: t.originalTexts.map((text, idx) => ({
                        bubbleIndex: idx,
                        original: text,
                        translated: '',
                        textDirection: t.autoDirections[idx] || 'vertical'
                    }))
                }
            }
        })

        // æ”¶é›†å›¾ç‰‡
        const imageBase64Array = tasks.map(t => {
            const dataUrl = isProofread
                ? (t.image.translatedDataURL || t.image.originalDataURL)
                : t.image.originalDataURL
            return extractBase64(dataUrl)
        })

        // è·å–é…ç½®
        const aiConfig = isProofread ? settings.proofreading.rounds[0] : settings.hqTranslation
        const prompt = isProofread ? aiConfig?.prompt : settings.hqTranslation.prompt
        const systemPrompt = isProofread
            ? 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ¼«ç”»ç¿»è¯‘æ ¡å¯¹åŠ©æ‰‹ï¼Œèƒ½å¤Ÿæ ¹æ®æ¼«ç”»å›¾åƒå†…å®¹æ£€æŸ¥å’Œä¿®æ­£ç¿»è¯‘ã€‚'
            : 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ¼«ç”»ç¿»è¯‘åŠ©æ‰‹ï¼Œèƒ½å¤Ÿæ ¹æ®æ¼«ç”»å›¾åƒå†…å®¹å’Œä¸Šä¸‹æ–‡æä¾›é«˜è´¨é‡çš„ç¿»è¯‘ã€‚'

        // æ„å»ºæ¶ˆæ¯
        const jsonString = JSON.stringify(jsonData, null, 2)
        type MessageContent = { type: 'text'; text: string } | { type: 'image_url'; image_url: { url: string } }
        const userContent: MessageContent[] = [
            {
                type: 'text',
                text: (prompt || '') + '\n\nä»¥ä¸‹æ˜¯JSONæ•°æ®:\n```json\n' + jsonString + '\n```'
            }
        ]
        for (const imgBase64 of imageBase64Array) {
            userContent.push({
                type: 'image_url',
                image_url: { url: `data:image/png;base64,${imgBase64}` }
            })
        }

        const messages = [
            { role: 'system' as const, content: systemPrompt },
            { role: 'user' as const, content: userContent }
        ]

        // è°ƒç”¨ API
        const hqConfig = settings.hqTranslation
        const roundConfig = isProofread ? aiConfig : null
        const response = await hqTranslateBatch({
            provider: (isProofread ? roundConfig?.provider : hqConfig.provider) || 'openai',
            api_key: (isProofread ? roundConfig?.apiKey : hqConfig.apiKey) || '',
            model_name: (isProofread ? roundConfig?.modelName : hqConfig.modelName) || '',
            custom_base_url: isProofread ? roundConfig?.customBaseUrl : hqConfig.customBaseUrl,
            messages,
            low_reasoning: isProofread ? roundConfig?.lowReasoning : hqConfig.lowReasoning,
            force_json_output: isProofread ? roundConfig?.forceJsonOutput : hqConfig.forceJsonOutput,
            no_thinking_method: isProofread ? roundConfig?.noThinkingMethod : hqConfig.noThinkingMethod,
            use_stream: isProofread ? false : hqConfig.useStream,
            max_retries: isProofread ? (settings.proofreading.maxRetries || 2) : (hqConfig.maxRetries || 2)
        })

        // è§£æç»“æœ
        const forceJson = isProofread ? (roundConfig?.forceJsonOutput || false) : hqConfig.forceJsonOutput
        const translatedData = parseHqResponse(response, forceJson)

        // æ ¡å¯¹æ¨¡å¼å¯èƒ½æœ‰å¤šè½®
        let currentData = translatedData || jsonData
        if (isProofread && settings.proofreading.rounds.length > 1) {
            for (let i = 1; i < settings.proofreading.rounds.length; i++) {
                const round = settings.proofreading.rounds[i]!
                const roundJsonString = JSON.stringify(currentData, null, 2)
                const roundUserContent: MessageContent[] = [
                    {
                        type: 'text',
                        text: round.prompt + '\n\nä»¥ä¸‹æ˜¯JSONæ•°æ®:\n```json\n' + roundJsonString + '\n```'
                    }
                ]
                for (const imgBase64 of imageBase64Array) {
                    roundUserContent.push({
                        type: 'image_url',
                        image_url: { url: `data:image/png;base64,${imgBase64}` }
                    })
                }

                const roundMessages = [
                    { role: 'system' as const, content: systemPrompt },
                    { role: 'user' as const, content: roundUserContent }
                ]

                const roundResponse = await hqTranslateBatch({
                    provider: round.provider,
                    api_key: round.apiKey,
                    model_name: round.modelName,
                    custom_base_url: round.customBaseUrl,
                    messages: roundMessages,
                    low_reasoning: round.lowReasoning,
                    force_json_output: round.forceJsonOutput,
                    no_thinking_method: round.noThinkingMethod,
                    use_stream: false,
                    max_retries: round.maxRetries || settings.proofreading.maxRetries || 2
                })

                const roundResult = parseHqResponse(roundResponse, round.forceJsonOutput)
                if (roundResult) {
                    currentData = roundResult
                }
            }
        }

        // å¡«å……ç»“æœ
        for (const t of tasks) {
            const taskData = (currentData as any[])?.find((d: any) => d.imageIndex === t.imageIndex)
            if (taskData) {
                t.translatedTexts = taskData.bubbles.map((b: any) => b.translated)
            } else {
                t.translatedTexts = []
            }
            t.textboxTexts = []
        }
    }

    async function executeInpaint(task: TaskState): Promise<void> {
        if (task.bubbleCoords.length === 0) {
            task.cleanImage = extractBase64(task.image.originalDataURL)
            return
        }

        const settings = settingsStore.settings
        const { textStyle, preciseMask } = settings
        const base64 = extractBase64(task.image.originalDataURL)

        const response: ParallelInpaintResponse = await parallelInpaint({
            image: base64,
            bubble_coords: task.bubbleCoords,
            bubble_polygons: task.bubblePolygons,
            raw_mask: task.rawMask,
            method: textStyle.inpaintMethod === 'solid' ? 'solid' : 'lama',
            lama_model: textStyle.inpaintMethod === 'litelama' ? 'litelama' : 'lama_mpe',
            fill_color: textStyle.fillColor,
            mask_dilate_size: preciseMask.dilateSize,
            mask_box_expand_ratio: preciseMask.boxExpandRatio
        })

        if (!response.success) {
            throw new Error(response.error || 'èƒŒæ™¯ä¿®å¤å¤±è´¥')
        }

        task.cleanImage = response.clean_image
    }

    async function executeRender(task: TaskState): Promise<void> {
        if (!task.cleanImage) {
            throw new Error('ç¼ºå°‘å¹²å‡€èƒŒæ™¯å›¾ç‰‡')
        }

        const { textStyle } = settingsStore.settings

        // ã€ç®€åŒ–è®¾è®¡ã€‘è®¡ç®— textDirectionï¼š
        // - å¦‚æœå…¨å±€è®¾ç½®æ˜¯ 'auto'ï¼Œä½¿ç”¨æ£€æµ‹ç»“æœ
        // - å¦åˆ™ä½¿ç”¨å…¨å±€è®¾ç½®çš„å€¼
        const globalTextDir = savedTextStyles?.autoTextDirection
            ? 'auto'  // autoTextDirection ä¸º true è¡¨ç¤ºç”¨æˆ·é€‰æ‹©äº† 'auto'
            : (savedTextStyles?.textDirection || textStyle.layoutDirection)

        // æ„å»º bubbleStates
        const bubbleStates: BubbleState[] = task.bubbleCoords.map((coords, idx) => {
            const autoDir = task.autoDirections[idx] || 'vertical'
            // å°†åç«¯è¿”å›çš„ 'v'/'h' æ ¼å¼è½¬æ¢ä¸º 'vertical'/'horizontal'
            const mappedAutoDir: 'vertical' | 'horizontal' = autoDir === 'v' ? 'vertical'
                : autoDir === 'h' ? 'horizontal'
                    : (autoDir === 'vertical' || autoDir === 'horizontal') ? autoDir : 'vertical'

            // ã€ç®€åŒ–è®¾è®¡ã€‘textDirection ç›´æ¥ä½¿ç”¨å…·ä½“æ–¹å‘å€¼
            const textDirection =
                (globalTextDir === 'vertical' || globalTextDir === 'horizontal')
                    ? globalTextDir
                    : mappedAutoDir

            return {
                coords,
                polygon: [] as number[][],
                position: { x: 0, y: 0 },
                rotationAngle: task.bubbleAngles[idx] || 0,
                originalText: task.originalTexts[idx] || '',
                translatedText: task.translatedTexts[idx] || '',
                textboxText: task.textboxTexts[idx] || '',
                textDirection: textDirection as 'vertical' | 'horizontal',  // æ¸²æŸ“ç”¨çš„å…·ä½“æ–¹å‘
                autoTextDirection: mappedAutoDir as 'vertical' | 'horizontal',  // å¤‡ä»½æ£€æµ‹ç»“æœ
                fontSize: savedTextStyles?.fontSize || textStyle.fontSize,
                fontFamily: savedTextStyles?.fontFamily || textStyle.fontFamily,
                autoFontSize: savedTextStyles?.autoFontSize ?? textStyle.autoFontSize,
                textColor: task.colors[idx]?.textColor || savedTextStyles?.textColor || textStyle.textColor,
                fillColor: savedTextStyles?.fillColor || textStyle.fillColor,
                strokeEnabled: savedTextStyles?.strokeEnabled ?? textStyle.strokeEnabled,
                strokeColor: savedTextStyles?.strokeColor || textStyle.strokeColor,
                strokeWidth: savedTextStyles?.strokeWidth || textStyle.strokeWidth,
                inpaintMethod: textStyle.inpaintMethod,
                autoFgColor: task.colors[idx]?.autoFgColor || null,
                autoBgColor: task.colors[idx]?.autoBgColor || null
            }
        })

        const response: ParallelRenderResponse = await parallelRender({
            clean_image: task.cleanImage,
            bubble_states: bubbleStates,
            fontSize: savedTextStyles?.fontSize || textStyle.fontSize,
            fontFamily: savedTextStyles?.fontFamily || textStyle.fontFamily,
            textDirection: savedTextStyles?.textDirection || textStyle.layoutDirection,
            textColor: savedTextStyles?.textColor || textStyle.textColor,
            strokeEnabled: savedTextStyles?.strokeEnabled ?? textStyle.strokeEnabled,
            strokeColor: savedTextStyles?.strokeColor || textStyle.strokeColor,
            strokeWidth: savedTextStyles?.strokeWidth || textStyle.strokeWidth,
            autoFontSize: savedTextStyles?.autoFontSize ?? textStyle.autoFontSize,
            use_individual_styles: true
        })

        if (!response.success) {
            throw new Error(response.error || 'æ¸²æŸ“å¤±è´¥')
        }

        task.finalImage = response.final_image
        task.bubbleStates = response.bubble_states || bubbleStates
    }

    // ============================================================
    // è¾…åŠ©å‡½æ•°
    // ============================================================

    function parseHqResponse(
        response: { success: boolean; results?: any[]; content?: string; error?: string },
        forceJsonOutput: boolean
    ): any[] | null {
        if (!response.success) {
            console.error('APIè°ƒç”¨å¤±è´¥:', response.error)
            return null
        }

        if (response.results && response.results.length > 0) {
            const firstItem = response.results[0]
            if (firstItem && 'imageIndex' in firstItem && 'bubbles' in firstItem) {
                return response.results
            }
        }

        const content = (response as { content?: string }).content
        if (content) {
            if (forceJsonOutput) {
                try {
                    return JSON.parse(content)
                } catch {
                    return null
                }
            } else {
                const jsonMatch = content.match(/```json\s*([\s\S]*?)\s*```/)
                if (jsonMatch?.[1]) {
                    try {
                        return JSON.parse(jsonMatch[1])
                    } catch {
                        return null
                    }
                }
            }
        }

        return null
    }

    function updateImageStore(task: TaskState): void {
        const translatedDataURL = task.finalImage
            ? `data:image/png;base64,${task.finalImage}`
            : task.cleanImage
                ? `data:image/png;base64,${task.cleanImage}`
                : null

        imageStore.updateImageByIndex(task.imageIndex, {
            translatedDataURL,
            cleanImageData: task.cleanImage || null,
            bubbleStates: task.bubbleStates,
            bubbleCoords: task.bubbleCoords,
            bubbleAngles: task.bubbleAngles,
            originalTexts: task.originalTexts,
            textboxTexts: task.textboxTexts,
            bubbleTexts: task.translatedTexts,
            translationStatus: 'completed',
            translationFailed: false,
            showOriginal: false,
            hasUnsavedChanges: true
        })

        if (task.imageIndex === imageStore.currentImageIndex && task.bubbleStates) {
            bubbleStore.setBubbles(task.bubbleStates)
        }
    }

    // ============================================================
    // ä¸»æ‰§è¡Œå‡½æ•°
    // ============================================================

    async function execute(config: PipelineConfig): Promise<PipelineResult> {
        if (!validateConfig(config)) {
            return { success: false, completed: 0, failed: 0, errors: ['é…ç½®éªŒè¯å¤±è´¥'] }
        }

        const images = imageStore.images
        if (images.length === 0) {
            toast.error('è¯·å…ˆä¸Šä¼ å›¾ç‰‡')
            return { success: false, completed: 0, failed: 0, errors: ['æ²¡æœ‰å›¾ç‰‡'] }
        }

        currentMode = config.mode
        const stepChain = STEP_CHAIN_CONFIGS[config.mode]
        console.log(`ğŸš€ é¡ºåºç®¡çº¿å¯åŠ¨ï¼Œæ¨¡å¼: ${config.mode}, æ­¥éª¤é“¾: [${stepChain.join(' â†’ ')}]`)

        isExecuting.value = true
        if (config.scope === 'all' || config.scope === 'failed') {
            imageStore.setBatchTranslationInProgress(true)
        }
        initRateLimiter()
        saveCurrentStyles()

        const imagesToProcess = getImagesToProcess(config)
        const errors: string[] = []
        let completed = 0
        let failed = 0

        // åˆ›å»ºä»»åŠ¡çŠ¶æ€
        const tasks: TaskState[] = imagesToProcess.map(({ image, index }) => ({
            imageIndex: index,
            image,
            bubbleCoords: [],
            bubbleAngles: [],
            bubblePolygons: [],
            autoDirections: [],
            textlinesPerBubble: [],
            originalTexts: [],
            colors: [],
            translatedTexts: [],
            textboxTexts: []
        }))

        try {
            reporter.init(imagesToProcess.length, `${config.mode} æ¨¡å¼å¯åŠ¨...`)

            for (let stepIdx = 0; stepIdx < stepChain.length; stepIdx++) {
                const step = stepChain[stepIdx]!
                const stepProgress = Math.floor((stepIdx / stepChain.length) * 90)
                reporter.setPercentage(stepProgress, `æ‰§è¡Œ: ${STEP_LABELS[step]}`)
                toast.info(`æ­¥éª¤ ${stepIdx + 1}/${stepChain.length}: ${STEP_LABELS[step]}...`)

                if (step === 'aiTranslate') {
                    // æ‰¹é‡æ­¥éª¤
                    await executeAiTranslate(tasks)
                } else {
                    // é€å¼ æ‰§è¡Œ
                    for (let i = 0; i < tasks.length; i++) {
                        const task = tasks[i]!

                        if (config.scope === 'all' && !imageStore.isBatchTranslationInProgress) {
                            break
                        }

                        if (rateLimiter.value) {
                            await rateLimiter.value.acquire()
                        }

                        try {
                            imageStore.setTranslationStatus(task.imageIndex, 'processing')

                            switch (step) {
                                case 'detection':
                                    await executeDetection(task)
                                    break
                                case 'ocr':
                                    await executeOcr(task)
                                    break
                                case 'color':
                                    await executeColor(task)
                                    break
                                case 'translate':
                                    await executeTranslate(task)
                                    break
                                case 'inpaint':
                                    await executeInpaint(task)
                                    break
                                case 'render':
                                    await executeRender(task)
                                    updateImageStore(task)
                                    break
                            }
                        } catch (err) {
                            const msg = err instanceof Error ? err.message : 'æœªçŸ¥é”™è¯¯'
                            errors.push(`å›¾ç‰‡ ${task.imageIndex}: ${step} - ${msg}`)
                            imageStore.setTranslationStatus(task.imageIndex, 'failed', msg)
                        }

                        const taskProgress = Math.floor(((i + 1) / tasks.length) * 100)
                        const overallProgress = stepProgress + Math.floor((taskProgress / 100) * (90 / stepChain.length))
                        reporter.setPercentage(overallProgress, `${STEP_LABELS[step]}: ${i + 1}/${tasks.length}`)
                    }
                }
            }

            // ç»Ÿè®¡ç»“æœ
            for (const task of tasks) {
                const status = imageStore.images[task.imageIndex]?.translationStatus
                if (status === 'completed') {
                    completed++
                } else if (status === 'failed') {
                    failed++
                } else {
                    if (!stepChain.includes('render')) {
                        updateImageStore(task)
                        completed++
                    }
                }
            }

            reporter.setPercentage(100, 'å®Œæˆï¼')

            const modeLabels: Record<TranslationMode, string> = {
                standard: 'ç¿»è¯‘',
                hq: 'é«˜è´¨é‡ç¿»è¯‘',
                proofread: 'AIæ ¡å¯¹',
                removeText: 'æ¶ˆé™¤æ–‡å­—'
            }
            toast.success(`${modeLabels[config.mode]}å®Œæˆï¼`)

            return {
                success: failed === 0,
                completed,
                failed,
                errors: errors.length > 0 ? errors : undefined
            }

        } catch (error) {
            const errorMessage = error instanceof Error ? error.message : 'æ‰§è¡Œå¤±è´¥'
            toast.error(errorMessage)
            errors.push(errorMessage)
            return {
                success: false,
                completed: 0,
                failed: imagesToProcess.length,
                errors
            }

        } finally {
            isExecuting.value = false
            imageStore.setBatchTranslationInProgress(false)

            const currentIndex = imageStore.currentImageIndex
            const currentImage = imageStore.images[currentIndex]
            if (currentImage?.bubbleStates && currentImage.bubbleStates.length > 0) {
                bubbleStore.setBubbles(currentImage.bubbleStates)
            }

            setTimeout(() => reporter.finish(), 1000)
        }
    }

    function cancel(): void {
        if (imageStore.isBatchTranslationInProgress) {
            imageStore.setBatchTranslationInProgress(false)
            toast.info('æ“ä½œå·²å–æ¶ˆ')
        }
    }

    return {
        progress,
        isExecuting,
        isTranslating,
        progressPercent,
        execute,
        cancel,
        STEP_CHAIN_CONFIGS
    }
}
