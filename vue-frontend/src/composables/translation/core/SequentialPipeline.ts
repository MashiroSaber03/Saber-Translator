/**
 * é¡ºåºç¿»è¯‘ç®¡çº¿ - åŸå­æ­¥éª¤ç‰ˆæœ¬
 * 
 * è®¾è®¡ç†å¿µï¼šä¸å¹¶è¡Œç®¡çº¿å®Œå…¨ä¸€è‡´çš„åŸå­æ­¥éª¤
 * 
 * 7ä¸ªåŸå­æ­¥éª¤ï¼š
 * 1. detection - æ°”æ³¡æ£€æµ‹
 * 2. ocr - æ–‡å­—è¯†åˆ«
 * 3. color - é¢œè‰²æå–
 * 4. translate - æ™®é€šç¿»è¯‘
 * 5. aiTranslate - AIç¿»è¯‘ï¼ˆé«˜è´¨é‡ç¿»è¯‘å’Œæ ¡å¯¹å…±ç”¨ï¼‰
 * 6. inpaint - èƒŒæ™¯ä¿®å¤
 * 7. render - æ¸²æŸ“è¯‘æ–‡
 */

import { ref, computed } from 'vue'
import { useImageStore } from '@/stores/imageStore'
import { useBubbleStore } from '@/stores/bubbleStore'
import { useSettingsStore } from '@/stores/settingsStore'
import { useValidation } from '../../useValidation'
import { useToast } from '@/utils/toast'
import { createRateLimiter, type RateLimiter } from '@/utils/rateLimiter'
import { createProgressManager } from './progressManager'
import type {
    PipelineConfig,
    PipelineResult,
    SavedTextStyles,
    TranslationMode
} from './types'
import type { ImageData as AppImageData } from '@/types/image'
import type { BubbleState, BubbleCoords } from '@/types/bubble'

// åˆ†æ­¥ API
import {
    parallelDetect,
    parallelOcr,
    parallelColor,
    parallelTranslate,
    parallelInpaint,
    parallelRender,
    type ParallelDetectResponse,
    type ParallelOcrResponse,
    type ParallelColorResponse,
    type ParallelTranslateResponse,
    type ParallelInpaintResponse,
    type ParallelRenderResponse
} from '@/api/parallelTranslate'
import { hqTranslateBatch } from '@/api/translate'

// è‡ªåŠ¨ä¿å­˜æ¨¡å—
import {
    shouldEnableAutoSave,
    preSaveOriginalImages,
    saveTranslatedImage,
    finalizeSave,
    resetSaveState
} from './saveStep'

// ============================================================
// åŸå­æ­¥éª¤ç±»å‹
// ============================================================

export type AtomicStepType =
    | 'detection'     // æ°”æ³¡æ£€æµ‹
    | 'ocr'           // æ–‡å­—è¯†åˆ«
    | 'color'         // é¢œè‰²æå–
    | 'translate'     // æ™®é€šç¿»è¯‘
    | 'aiTranslate'   // AIç¿»è¯‘ï¼ˆé«˜è´¨é‡ç¿»è¯‘ & æ ¡å¯¹å…±ç”¨ï¼‰
    | 'inpaint'       // èƒŒæ™¯ä¿®å¤
    | 'render'        // æ¸²æŸ“
    | 'save'          // è‡ªåŠ¨ä¿å­˜ï¼ˆä¹¦æ¶æ¨¡å¼ï¼‰

/**
 * æ­¥éª¤é“¾é…ç½®
 */
export const STEP_CHAIN_CONFIGS: Record<TranslationMode, AtomicStepType[]> = {
    standard: ['detection', 'ocr', 'color', 'translate', 'inpaint', 'render'],
    hq: ['detection', 'ocr', 'color', 'aiTranslate', 'inpaint', 'render'],
    proofread: ['aiTranslate', 'render'],
    removeText: ['detection', 'inpaint', 'render']
}

/** æ­¥éª¤æ˜¾ç¤ºåç§° */
const STEP_LABELS: Record<AtomicStepType, string> = {
    detection: 'æ°”æ³¡æ£€æµ‹',
    ocr: 'æ–‡å­—è¯†åˆ«',
    color: 'é¢œè‰²æå–',
    translate: 'ç¿»è¯‘',
    aiTranslate: 'AIç¿»è¯‘',
    inpaint: 'èƒŒæ™¯ä¿®å¤',
    render: 'æ¸²æŸ“',
    save: 'ä¿å­˜'
}

// ============================================================
// ä»»åŠ¡çŠ¶æ€
// ============================================================

interface TaskState {
    imageIndex: number
    image: AppImageData

    // æ£€æµ‹ç»“æœ
    bubbleCoords: BubbleCoords[]
    bubbleAngles: number[]
    bubblePolygons: number[][][]
    autoDirections: string[]
    rawMask?: string
    textlinesPerBubble: any[]

    // OCRç»“æœ
    originalTexts: string[]

    // é¢œè‰²ç»“æœ
    colors: Array<{
        textColor: string
        bgColor: string
        autoFgColor?: [number, number, number] | null
        autoBgColor?: [number, number, number] | null
    }>

    // ç¿»è¯‘ç»“æœ
    translatedTexts: string[]
    textboxTexts: string[]

    // ä¿®å¤ç»“æœ
    cleanImage?: string

    // æ¸²æŸ“ç»“æœ
    finalImage?: string
    bubbleStates?: BubbleState[]
}

// ============================================================
// é¡ºåºç®¡çº¿ Composable
// ============================================================

export function useSequentialPipeline() {
    const imageStore = useImageStore()
    const bubbleStore = useBubbleStore()
    const settingsStore = useSettingsStore()
    const validation = useValidation()
    const toast = useToast()

    const { progress, reporter } = createProgressManager()
    const isExecuting = ref(false)
    const rateLimiter = ref<RateLimiter | null>(null)
    let savedTextStyles: SavedTextStyles | null = null
    let currentMode: TranslationMode = 'standard'

    const isTranslating = computed(() => isExecuting.value || imageStore.isBatchTranslationInProgress)
    const progressPercent = computed(() => progress.value.percentage || 0)

    // ============================================================
    // å·¥å…·å‡½æ•°
    // ============================================================

    function initRateLimiter(): void {
        const rpm = settingsStore.settings.translation.rpmLimit
        if (!rateLimiter.value) {
            rateLimiter.value = createRateLimiter(rpm)
        } else {
            rateLimiter.value.setRpm(rpm)
        }
    }

    function validateConfig(config: PipelineConfig): boolean {
        const validationType = config.mode === 'hq' ? 'hq'
            : config.mode === 'proofread' ? 'proofread'
                : config.mode === 'removeText' ? 'ocr'
                    : 'normal'
        return validation.validateBeforeTranslation(validationType)
    }

    function saveCurrentStyles(): void {
        const { textStyle } = settingsStore.settings
        const layoutDirectionValue = textStyle.layoutDirection
        savedTextStyles = {
            fontFamily: textStyle.fontFamily,
            fontSize: textStyle.fontSize,
            autoFontSize: textStyle.autoFontSize,
            autoTextDirection: layoutDirectionValue === 'auto',
            textDirection: layoutDirectionValue === 'auto' ? 'vertical' : layoutDirectionValue,
            layoutDirection: layoutDirectionValue,  // ä¿å­˜ç”¨æˆ·åŸå§‹é€‰æ‹©ï¼ˆåŒ…æ‹¬ 'auto'ï¼‰
            fillColor: textStyle.fillColor,
            textColor: textStyle.textColor,
            rotationAngle: 0,
            strokeEnabled: textStyle.strokeEnabled,
            strokeColor: textStyle.strokeColor,
            strokeWidth: textStyle.strokeWidth,
            useAutoTextColor: textStyle.useAutoTextColor,
            inpaintMethod: textStyle.inpaintMethod
        }
    }

    function extractBase64(dataUrl: string): string {
        if (dataUrl.includes('base64,')) {
            return dataUrl.split('base64,')[1] || ''
        }
        return dataUrl
    }

    function getImagesToProcess(config: PipelineConfig): { image: AppImageData; index: number }[] {
        const images = imageStore.images
        if (config.scope === 'current') {
            const currentImage = imageStore.currentImage
            return currentImage ? [{ image: currentImage, index: imageStore.currentImageIndex }] : []
        }
        if (config.scope === 'failed') {
            return imageStore.getFailedImageIndices()
                .map(index => ({ image: images[index]!, index }))
                .filter(item => item.image !== undefined)
        }
        if (config.scope === 'range' && config.pageRange) {
            // é¡µç ä»1å¼€å§‹ï¼Œè½¬æ¢ä¸º0ç´¢å¼•
            const startIndex = Math.max(0, config.pageRange.startPage - 1)
            const endIndex = Math.min(images.length - 1, config.pageRange.endPage - 1)

            if (startIndex > endIndex || startIndex >= images.length) {
                return []
            }

            return images
                .slice(startIndex, endIndex + 1)
                .map((image, idx) => ({ image, index: startIndex + idx }))
        }
        return images.map((image, index) => ({ image, index }))
    }

    // ============================================================
    // åŸå­æ­¥éª¤æ‰§è¡Œå™¨
    // ============================================================

    async function executeDetection(task: TaskState): Promise<void> {
        const settings = settingsStore.settings
        const base64 = extractBase64(task.image.originalDataURL)

        const response: ParallelDetectResponse = await parallelDetect({
            image: base64,
            detector_type: settings.textDetector,
            box_expand_ratio: settings.boxExpand.ratio,
            box_expand_top: settings.boxExpand.top,
            box_expand_bottom: settings.boxExpand.bottom,
            box_expand_left: settings.boxExpand.left,
            box_expand_right: settings.boxExpand.right
        })

        if (!response.success) {
            throw new Error(response.error || 'æ£€æµ‹å¤±è´¥')
        }

        task.bubbleCoords = (response.bubble_coords || []) as BubbleCoords[]
        task.bubbleAngles = response.bubble_angles || []
        task.bubblePolygons = response.bubble_polygons || []
        task.autoDirections = response.auto_directions || []
        task.rawMask = response.raw_mask
        task.textlinesPerBubble = response.textlines_per_bubble || []
    }

    async function executeOcr(task: TaskState): Promise<void> {
        if (task.bubbleCoords.length === 0) {
            task.originalTexts = []
            return
        }

        const settings = settingsStore.settings
        const base64 = extractBase64(task.image.originalDataURL)

        // PaddleOCR-VL ä½¿ç”¨ç‹¬ç«‹çš„æºè¯­è¨€è®¾ç½®
        const ocrSourceLanguage = settings.ocrEngine === 'paddleocr_vl'
            ? settings.paddleOcrVl?.sourceLanguage || 'japanese'
            : settings.sourceLanguage

        const response: ParallelOcrResponse = await parallelOcr({
            image: base64,
            bubble_coords: task.bubbleCoords,
            source_language: ocrSourceLanguage,
            ocr_engine: settings.ocrEngine,
            baidu_api_key: settings.baiduOcr?.apiKey,
            baidu_secret_key: settings.baiduOcr?.secretKey,
            baidu_version: settings.baiduOcr?.version,
            baidu_ocr_language: settings.baiduOcr?.sourceLanguage,
            ai_vision_provider: settings.aiVisionOcr?.provider,
            ai_vision_api_key: settings.aiVisionOcr?.apiKey,
            ai_vision_model_name: settings.aiVisionOcr?.modelName,
            ai_vision_ocr_prompt: settings.aiVisionOcr?.prompt,
            custom_ai_vision_base_url: settings.aiVisionOcr?.customBaseUrl,
            textlines_per_bubble: task.textlinesPerBubble
        })

        if (!response.success) {
            throw new Error(response.error || 'OCRå¤±è´¥')
        }

        task.originalTexts = response.original_texts || []
    }

    async function executeColor(task: TaskState): Promise<void> {
        if (task.bubbleCoords.length === 0) {
            task.colors = []
            return
        }

        const base64 = extractBase64(task.image.originalDataURL)

        const response: ParallelColorResponse = await parallelColor({
            image: base64,
            bubble_coords: task.bubbleCoords,
            textlines_per_bubble: task.textlinesPerBubble
        })

        if (!response.success) {
            throw new Error(response.error || 'é¢œè‰²æå–å¤±è´¥')
        }

        task.colors = response.colors || []
    }

    async function executeTranslate(task: TaskState): Promise<void> {
        if (task.originalTexts.length === 0) {
            task.translatedTexts = []
            task.textboxTexts = []
            return
        }

        const settings = settingsStore.settings

        const response: ParallelTranslateResponse = await parallelTranslate({
            original_texts: task.originalTexts,
            target_language: settings.targetLanguage,
            source_language: settings.sourceLanguage,
            model_provider: settings.translation.provider,
            model_name: settings.translation.modelName,
            api_key: settings.translation.apiKey,
            custom_base_url: settings.translation.customBaseUrl,
            prompt_content: settings.translatePrompt,
            textbox_prompt_content: settings.textboxPrompt,
            use_textbox_prompt: settings.useTextboxPrompt,
            rpm_limit: settings.translation.rpmLimit,
            max_retries: settings.translation.maxRetries,
            use_json_format: settings.translation.isJsonMode
        })

        if (!response.success) {
            throw new Error(response.error || 'ç¿»è¯‘å¤±è´¥')
        }

        task.translatedTexts = response.translated_texts || []
        task.textboxTexts = response.textbox_texts || []
    }

    /**
     * AIç¿»è¯‘æ­¥éª¤ï¼ˆé«˜è´¨é‡ç¿»è¯‘ & æ ¡å¯¹å…±ç”¨ï¼‰
     * æ ¹æ® currentMode å†³å®šä½¿ç”¨å“ªç§é…ç½®
     */
    async function executeAiTranslate(tasks: TaskState[]): Promise<void> {
        const settings = settingsStore.settings
        const isProofread = currentMode === 'proofread'

        // æ”¶é›† JSON æ•°æ®
        const jsonData = tasks.map(t => {
            if (isProofread) {
                // æ ¡å¯¹æ¨¡å¼ï¼šä½¿ç”¨å·²æœ‰è¯‘æ–‡
                return {
                    imageIndex: t.imageIndex,
                    bubbles: (t.image.bubbleStates || []).map((state, idx) => ({
                        bubbleIndex: idx,
                        original: state.originalText || '',
                        translated: settings.useTextboxPrompt
                            ? (state.textboxText || state.translatedText || '')
                            : (state.translatedText || ''),
                        // ã€ç®€åŒ–è®¾è®¡ã€‘ç›´æ¥ä½¿ç”¨ textDirectionï¼Œå®ƒå·²ç»æ˜¯å…·ä½“æ–¹å‘å€¼
                        textDirection: (state.textDirection === 'vertical' || state.textDirection === 'horizontal')
                            ? state.textDirection
                            : (state.autoTextDirection === 'vertical' || state.autoTextDirection === 'horizontal')
                                ? state.autoTextDirection
                                : 'vertical'
                    }))
                }
            } else {
                // é«˜è´¨é‡ç¿»è¯‘ï¼šä½¿ç”¨ OCR ç»“æœ
                return {
                    imageIndex: t.imageIndex,
                    bubbles: t.originalTexts.map((text, idx) => ({
                        bubbleIndex: idx,
                        original: text,
                        translated: '',
                        textDirection: t.autoDirections[idx] || 'vertical'
                    }))
                }
            }
        })

        // æ”¶é›†å›¾ç‰‡
        const imageBase64Array = tasks.map(t => {
            const dataUrl = isProofread
                ? (t.image.translatedDataURL || t.image.originalDataURL)
                : t.image.originalDataURL
            return extractBase64(dataUrl)
        })

        // è·å–é…ç½®
        const aiConfig = isProofread ? settings.proofreading.rounds[0] : settings.hqTranslation
        const prompt = isProofread ? aiConfig?.prompt : settings.hqTranslation.prompt
        const systemPrompt = isProofread
            ? 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ¼«ç”»ç¿»è¯‘æ ¡å¯¹åŠ©æ‰‹ï¼Œèƒ½å¤Ÿæ ¹æ®æ¼«ç”»å›¾åƒå†…å®¹æ£€æŸ¥å’Œä¿®æ­£ç¿»è¯‘ã€‚'
            : 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ¼«ç”»ç¿»è¯‘åŠ©æ‰‹ï¼Œèƒ½å¤Ÿæ ¹æ®æ¼«ç”»å›¾åƒå†…å®¹å’Œä¸Šä¸‹æ–‡æä¾›é«˜è´¨é‡çš„ç¿»è¯‘ã€‚'

        // æ„å»ºæ¶ˆæ¯
        const jsonString = JSON.stringify(jsonData, null, 2)
        type MessageContent = { type: 'text'; text: string } | { type: 'image_url'; image_url: { url: string } }
        const userContent: MessageContent[] = [
            {
                type: 'text',
                text: (prompt || '') + '\n\nä»¥ä¸‹æ˜¯JSONæ•°æ®:\n```json\n' + jsonString + '\n```'
            }
        ]
        for (const imgBase64 of imageBase64Array) {
            userContent.push({
                type: 'image_url',
                image_url: { url: `data:image/png;base64,${imgBase64}` }
            })
        }

        const messages = [
            { role: 'system' as const, content: systemPrompt },
            { role: 'user' as const, content: userContent }
        ]

        // è°ƒç”¨ API
        const hqConfig = settings.hqTranslation
        const roundConfig = isProofread ? aiConfig : null
        const response = await hqTranslateBatch({
            provider: (isProofread ? roundConfig?.provider : hqConfig.provider) || 'openai',
            api_key: (isProofread ? roundConfig?.apiKey : hqConfig.apiKey) || '',
            model_name: (isProofread ? roundConfig?.modelName : hqConfig.modelName) || '',
            custom_base_url: isProofread ? roundConfig?.customBaseUrl : hqConfig.customBaseUrl,
            messages,
            low_reasoning: isProofread ? roundConfig?.lowReasoning : hqConfig.lowReasoning,
            force_json_output: isProofread ? roundConfig?.forceJsonOutput : hqConfig.forceJsonOutput,
            no_thinking_method: isProofread ? roundConfig?.noThinkingMethod : hqConfig.noThinkingMethod,
            use_stream: isProofread ? false : hqConfig.useStream,
            max_retries: isProofread ? (settings.proofreading.maxRetries || 2) : (hqConfig.maxRetries || 2)
        })

        // è§£æç»“æœ
        const forceJson = isProofread ? (roundConfig?.forceJsonOutput || false) : hqConfig.forceJsonOutput
        const translatedData = parseHqResponse(response, forceJson)

        // æ ¡å¯¹æ¨¡å¼å¯èƒ½æœ‰å¤šè½®
        let currentData = translatedData || jsonData
        if (isProofread && settings.proofreading.rounds.length > 1) {
            for (let i = 1; i < settings.proofreading.rounds.length; i++) {
                const round = settings.proofreading.rounds[i]!
                const roundJsonString = JSON.stringify(currentData, null, 2)
                const roundUserContent: MessageContent[] = [
                    {
                        type: 'text',
                        text: round.prompt + '\n\nä»¥ä¸‹æ˜¯JSONæ•°æ®:\n```json\n' + roundJsonString + '\n```'
                    }
                ]
                for (const imgBase64 of imageBase64Array) {
                    roundUserContent.push({
                        type: 'image_url',
                        image_url: { url: `data:image/png;base64,${imgBase64}` }
                    })
                }

                const roundMessages = [
                    { role: 'system' as const, content: systemPrompt },
                    { role: 'user' as const, content: roundUserContent }
                ]

                const roundResponse = await hqTranslateBatch({
                    provider: round.provider,
                    api_key: round.apiKey,
                    model_name: round.modelName,
                    custom_base_url: round.customBaseUrl,
                    messages: roundMessages,
                    low_reasoning: round.lowReasoning,
                    force_json_output: round.forceJsonOutput,
                    no_thinking_method: round.noThinkingMethod,
                    use_stream: false,
                    max_retries: round.maxRetries || settings.proofreading.maxRetries || 2
                })

                const roundResult = parseHqResponse(roundResponse, round.forceJsonOutput)
                if (roundResult) {
                    currentData = roundResult
                }
            }
        }

        // å¡«å……ç»“æœ
        for (const t of tasks) {
            const taskData = (currentData as any[])?.find((d: any) => d.imageIndex === t.imageIndex)
            if (taskData) {
                t.translatedTexts = taskData.bubbles.map((b: any) => b.translated)
            } else {
                t.translatedTexts = []
            }
            t.textboxTexts = []
        }
    }

    async function executeInpaint(task: TaskState): Promise<void> {
        if (task.bubbleCoords.length === 0) {
            task.cleanImage = extractBase64(task.image.originalDataURL)
            return
        }

        const settings = settingsStore.settings
        const { textStyle, preciseMask } = settings
        const base64 = extractBase64(task.image.originalDataURL)

        const response: ParallelInpaintResponse = await parallelInpaint({
            image: base64,
            bubble_coords: task.bubbleCoords,
            bubble_polygons: task.bubblePolygons,
            raw_mask: task.rawMask,
            method: textStyle.inpaintMethod === 'solid' ? 'solid' : 'lama',
            lama_model: textStyle.inpaintMethod === 'litelama' ? 'litelama' : 'lama_mpe',
            fill_color: textStyle.fillColor,
            mask_dilate_size: preciseMask.dilateSize,
            mask_box_expand_ratio: preciseMask.boxExpandRatio
        })

        if (!response.success) {
            throw new Error(response.error || 'èƒŒæ™¯ä¿®å¤å¤±è´¥')
        }

        task.cleanImage = response.clean_image
    }

    async function executeRender(task: TaskState): Promise<void> {
        if (!task.cleanImage) {
            // æ ¡å¯¹æ¨¡å¼ä¸‹ï¼Œå¦‚æœæ²¡æœ‰å¹²å‡€èƒŒæ™¯å›¾ï¼Œè¯´æ˜å›¾ç‰‡æ²¡æœ‰è¢«ç¿»è¯‘è¿‡
            if (currentMode === 'proofread') {
                throw new Error('æ­¤å›¾ç‰‡å°šæœªç¿»è¯‘ï¼Œè¯·å…ˆç¿»è¯‘åå†è¿›è¡Œæ ¡å¯¹')
            }
            throw new Error('ç¼ºå°‘å¹²å‡€èƒŒæ™¯å›¾ç‰‡')
        }

        const { textStyle } = settingsStore.settings

        // ã€ç®€åŒ–è®¾è®¡ã€‘è®¡ç®— textDirectionï¼š
        // - å¦‚æœå…¨å±€è®¾ç½®æ˜¯ 'auto'ï¼Œä½¿ç”¨æ£€æµ‹ç»“æœ
        // - å¦åˆ™ä½¿ç”¨å…¨å±€è®¾ç½®çš„å€¼
        const globalTextDir = savedTextStyles?.autoTextDirection
            ? 'auto'  // autoTextDirection ä¸º true è¡¨ç¤ºç”¨æˆ·é€‰æ‹©äº† 'auto'
            : (savedTextStyles?.textDirection || textStyle.layoutDirection)

        // æ„å»º bubbleStates
        const bubbleStates: BubbleState[] = task.bubbleCoords.map((coords, idx) => {
            const autoDir = task.autoDirections[idx] || 'vertical'
            // å°†åç«¯è¿”å›çš„ 'v'/'h' æ ¼å¼è½¬æ¢ä¸º 'vertical'/'horizontal'
            const mappedAutoDir: 'vertical' | 'horizontal' = autoDir === 'v' ? 'vertical'
                : autoDir === 'h' ? 'horizontal'
                    : (autoDir === 'vertical' || autoDir === 'horizontal') ? autoDir : 'vertical'

            // ã€ç®€åŒ–è®¾è®¡ã€‘textDirection ç›´æ¥ä½¿ç”¨å…·ä½“æ–¹å‘å€¼
            const textDirection =
                (globalTextDir === 'vertical' || globalTextDir === 'horizontal')
                    ? globalTextDir
                    : mappedAutoDir

            // ã€ä¿®å¤ã€‘é¢œè‰²å¤„ç†ï¼šæ ¹æ® useAutoTextColor è®¾ç½®å†³å®šæ˜¯å¦ä½¿ç”¨è‡ªåŠ¨æå–çš„é¢œè‰²
            const useAutoColor = savedTextStyles?.useAutoTextColor ?? textStyle.useAutoTextColor
            let finalTextColor = savedTextStyles?.textColor || textStyle.textColor
            let finalFillColor = savedTextStyles?.fillColor || textStyle.fillColor
            const colorInfo = task.colors[idx]

            if (useAutoColor && colorInfo) {
                if (colorInfo.textColor) finalTextColor = colorInfo.textColor
                if (colorInfo.bgColor) finalFillColor = colorInfo.bgColor
            }

            return {
                coords,
                polygon: [] as number[][],
                position: { x: 0, y: 0 },
                rotationAngle: task.bubbleAngles[idx] || 0,
                originalText: task.originalTexts[idx] || '',
                translatedText: task.translatedTexts[idx] || '',
                textboxText: task.textboxTexts[idx] || '',
                textDirection: textDirection as 'vertical' | 'horizontal',  // æ¸²æŸ“ç”¨çš„å…·ä½“æ–¹å‘
                autoTextDirection: mappedAutoDir as 'vertical' | 'horizontal',  // å¤‡ä»½æ£€æµ‹ç»“æœ
                fontSize: savedTextStyles?.fontSize || textStyle.fontSize,
                fontFamily: savedTextStyles?.fontFamily || textStyle.fontFamily,
                autoFontSize: savedTextStyles?.autoFontSize ?? textStyle.autoFontSize,
                textColor: finalTextColor,
                fillColor: finalFillColor,
                strokeEnabled: savedTextStyles?.strokeEnabled ?? textStyle.strokeEnabled,
                strokeColor: savedTextStyles?.strokeColor || textStyle.strokeColor,
                strokeWidth: savedTextStyles?.strokeWidth || textStyle.strokeWidth,
                inpaintMethod: savedTextStyles?.inpaintMethod || textStyle.inpaintMethod,
                autoFgColor: task.colors[idx]?.autoFgColor || null,
                autoBgColor: task.colors[idx]?.autoBgColor || null
            }
        })

        const response: ParallelRenderResponse = await parallelRender({
            clean_image: task.cleanImage,
            bubble_states: bubbleStates,
            fontSize: savedTextStyles?.fontSize || textStyle.fontSize,
            fontFamily: savedTextStyles?.fontFamily || textStyle.fontFamily,
            textDirection: savedTextStyles?.textDirection || textStyle.layoutDirection,
            textColor: savedTextStyles?.textColor || textStyle.textColor,
            strokeEnabled: savedTextStyles?.strokeEnabled ?? textStyle.strokeEnabled,
            strokeColor: savedTextStyles?.strokeColor || textStyle.strokeColor,
            strokeWidth: savedTextStyles?.strokeWidth || textStyle.strokeWidth,
            autoFontSize: savedTextStyles?.autoFontSize ?? textStyle.autoFontSize,
            use_individual_styles: true
        })

        if (!response.success) {
            throw new Error(response.error || 'æ¸²æŸ“å¤±è´¥')
        }

        task.finalImage = response.final_image
        task.bubbleStates = response.bubble_states || bubbleStates
    }

    // ============================================================
    // è¾…åŠ©å‡½æ•°
    // ============================================================

    /**
     * æ‰§è¡Œå•ä¸ªæ­¥éª¤ï¼ˆé€šç”¨å‡½æ•°ï¼Œæ¶ˆé™¤é‡å¤ä»£ç ï¼‰
     * æ³¨æ„ï¼šaiTranslate æ­¥éª¤åœ¨ executeBatchMode ä¸­æœ‰ç‰¹æ®Šå¤„ç†ï¼Œä¸ä¼šé€šè¿‡æ­¤å‡½æ•°è°ƒç”¨
     */
    async function executeStep(step: AtomicStepType, task: TaskState): Promise<void> {
        switch (step) {
            case 'detection':
                await executeDetection(task)
                break
            case 'ocr':
                await executeOcr(task)
                break
            case 'color':
                await executeColor(task)
                break
            case 'translate':
                await executeTranslate(task)
                break
            case 'inpaint':
                await executeInpaint(task)
                break
            case 'render':
                await executeRender(task)
                break
            case 'save':
                // ä¿å­˜æ­¥éª¤ï¼šä¿å­˜å½“å‰å·²æ¸²æŸ“çš„å›¾ç‰‡ï¼ˆä»…ä¹¦æ¶æ¨¡å¼ï¼‰
                await saveTranslatedImage(task.imageIndex)
                break
            case 'aiTranslate':
                // æ­¤åˆ†æ”¯ä»…ä½œä¸ºç±»å‹å®Œæ•´æ€§ä¿ç•™ï¼Œå®é™…ä¸ä¼šè¢«è°ƒç”¨
                // aiTranslate åœ¨ executeBatchMode ä¸­æœ‰æ‰¹é‡å¤„ç†é€»è¾‘
                throw new Error('aiTranslate åº”é€šè¿‡æ‰¹é‡å¤„ç†é€»è¾‘è°ƒç”¨')
        }
    }

    function parseHqResponse(
        response: { success: boolean; results?: any[]; content?: string; error?: string },
        forceJsonOutput: boolean
    ): any[] | null {
        if (!response.success) {
            console.error('APIè°ƒç”¨å¤±è´¥:', response.error)
            return null
        }

        if (response.results && response.results.length > 0) {
            const firstItem = response.results[0]
            if (firstItem && 'imageIndex' in firstItem && 'bubbles' in firstItem) {
                return response.results
            }
        }

        const content = (response as { content?: string }).content
        if (content) {
            if (forceJsonOutput) {
                try {
                    return JSON.parse(content)
                } catch {
                    return null
                }
            } else {
                const jsonMatch = content.match(/```json\s*([\s\S]*?)\s*```/)
                if (jsonMatch?.[1]) {
                    try {
                        return JSON.parse(jsonMatch[1])
                    } catch {
                        return null
                    }
                }
            }
        }

        return null
    }

    function updateImageStore(task: TaskState): void {
        const translatedDataURL = task.finalImage
            ? `data:image/png;base64,${task.finalImage}`
            : task.cleanImage
                ? `data:image/png;base64,${task.cleanImage}`
                : null

        const { textStyle } = settingsStore.settings

        imageStore.updateImageByIndex(task.imageIndex, {
            translatedDataURL,
            cleanImageData: task.cleanImage || null,
            bubbleStates: task.bubbleStates,
            bubbleCoords: task.bubbleCoords,
            bubbleAngles: task.bubbleAngles,
            originalTexts: task.originalTexts,
            textboxTexts: task.textboxTexts,
            bubbleTexts: task.translatedTexts,
            translationStatus: 'completed',
            translationFailed: false,
            showOriginal: false,
            hasUnsavedChanges: true,
            // ä¿å­˜ç”¨æˆ·ç¿»è¯‘æ—¶é€‰æ‹©çš„è®¾ç½®ï¼ˆç”¨äºåˆ‡æ¢å›¾ç‰‡æ—¶æ¢å¤ï¼‰
            // ã€ä¿®å¤ã€‘ä¿å­˜å®Œæ•´çš„æ–‡å­—è®¾ç½®ï¼Œé¿å…åˆ‡æ¢å›¾ç‰‡åä¾§è¾¹æ æ˜¾ç¤ºé»˜è®¤å€¼
            fontSize: savedTextStyles?.fontSize ?? textStyle.fontSize,
            autoFontSize: savedTextStyles?.autoFontSize ?? textStyle.autoFontSize,
            fontFamily: savedTextStyles?.fontFamily ?? textStyle.fontFamily,
            layoutDirection: savedTextStyles?.layoutDirection ?? textStyle.layoutDirection,
            textColor: savedTextStyles?.textColor ?? textStyle.textColor,
            fillColor: savedTextStyles?.fillColor ?? textStyle.fillColor,
            strokeEnabled: savedTextStyles?.strokeEnabled ?? textStyle.strokeEnabled,
            strokeColor: savedTextStyles?.strokeColor ?? textStyle.strokeColor,
            strokeWidth: savedTextStyles?.strokeWidth ?? textStyle.strokeWidth,
            inpaintMethod: savedTextStyles?.inpaintMethod ?? textStyle.inpaintMethod,
            useAutoTextColor: savedTextStyles?.useAutoTextColor ?? textStyle.useAutoTextColor
        })

        if (task.imageIndex === imageStore.currentImageIndex && task.bubbleStates) {
            bubbleStore.setBubbles(task.bubbleStates)
        }
    }

    // ============================================================
    // ä¸»æ‰§è¡Œå‡½æ•°
    // ============================================================

    /**
     * åˆ¤æ–­æ˜¯å¦ä½¿ç”¨é€å¼ å¤„ç†æ¨¡å¼
     * - standard / removeText: é€å¼ å¤„ç†ï¼ˆæ¯å¼ å›¾å®Œæˆå…¨éƒ¨æ­¥éª¤åå†å¤„ç†ä¸‹ä¸€å¼ ï¼‰
     * - hq / proofread: æŒ‰æ‰¹æ¬¡å¤„ç†ï¼ˆæ‰¹æ¬¡å†…ä¿æŒæŒ‰æ­¥éª¤æ‰¹é‡å¤„ç†ï¼‰
     */
    function shouldUsePerImageMode(mode: TranslationMode): boolean {
        return mode === 'standard' || mode === 'removeText'
    }

    /**
     * è·å–æ‰¹æ¬¡å¤§å°é…ç½®
     * ä»…åœ¨ executeBatchMode ä¸­è°ƒç”¨ï¼Œç”¨äº hq å’Œ proofread æ¨¡å¼
     */
    function getBatchSize(mode: TranslationMode): number {
        const settings = settingsStore.settings
        if (mode === 'hq') {
            return settings.hqTranslation.batchSize || 5
        }
        if (mode === 'proofread') {
            // ä½¿ç”¨ç¬¬ä¸€è½®æ ¡å¯¹çš„æ‰¹æ¬¡å¤§å°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
            return settings.proofreading.rounds[0]?.batchSize || 5
        }
        // é˜²å¾¡æ€§ä»£ç ï¼šstandard å’Œ removeText æ¨¡å¼ä¸åº”è°ƒç”¨æ­¤å‡½æ•°
        return 1
    }

    /**
     * é€å¼ å¤„ç†æ¨¡å¼ï¼ˆæ ‡å‡†ç¿»è¯‘/æ¶ˆé™¤æ–‡å­—ï¼‰
     * æ¯å¼ å›¾ç‰‡èµ°å®Œå…¨éƒ¨æ­¥éª¤åå†å¤„ç†ä¸‹ä¸€å¼ 
     */
    async function executePerImageMode(
        tasks: TaskState[],
        stepChain: AtomicStepType[],
        config: PipelineConfig,
        errors: string[]
    ): Promise<{ completed: number; failed: number }> {
        let completed = 0
        let failed = 0

        for (let imageIdx = 0; imageIdx < tasks.length; imageIdx++) {
            const task = tasks[imageIdx]!

            // æ£€æŸ¥æ˜¯å¦å–æ¶ˆ
            if (config.scope === 'all' && !imageStore.isBatchTranslationInProgress) {
                console.log(`â¹ï¸ æ‰¹é‡ç¿»è¯‘å·²å–æ¶ˆï¼Œåœæ­¢å¤„ç†`)
                break
            }

            const imageProgress = Math.floor((imageIdx / tasks.length) * 90)
            reporter.setPercentage(imageProgress, `å¤„ç†å›¾ç‰‡ ${imageIdx + 1}/${tasks.length}`)
            toast.info(`å¤„ç†å›¾ç‰‡ ${imageIdx + 1}/${tasks.length}...`)

            imageStore.setTranslationStatus(task.imageIndex, 'processing')
            let taskFailed = false

            // å¯¹å½“å‰å›¾ç‰‡æ‰§è¡Œå…¨éƒ¨æ­¥éª¤
            for (let stepIdx = 0; stepIdx < stepChain.length; stepIdx++) {
                const step = stepChain[stepIdx]!

                if (taskFailed) break

                if (rateLimiter.value) {
                    await rateLimiter.value.acquire()
                }

                try {
                    const stepProgress = imageProgress + Math.floor((stepIdx / stepChain.length) * (90 / tasks.length))
                    reporter.setPercentage(stepProgress, `å›¾ç‰‡ ${imageIdx + 1}: ${STEP_LABELS[step]}`)

                    await executeStep(step, task)
                } catch (err) {
                    const msg = err instanceof Error ? err.message : 'æœªçŸ¥é”™è¯¯'
                    errors.push(`å›¾ç‰‡ ${task.imageIndex + 1}: ${step} - ${msg}`)
                    imageStore.setTranslationStatus(task.imageIndex, 'failed', msg)
                    taskFailed = true
                    failed++
                }
            }

            // è¿™å¼ å›¾ç‰‡å¤„ç†å®Œæˆï¼Œç«‹å³æ›´æ–° store
            if (!taskFailed) {
                updateImageStore(task)
                completed++
                console.log(`âœ… å›¾ç‰‡ ${imageIdx + 1}/${tasks.length} å¤„ç†å®Œæˆ`)
            }
        }

        return { completed, failed }
    }

    /**
     * æ‰¹æ¬¡å¤„ç†æ¨¡å¼ï¼ˆé«˜è´¨é‡ç¿»è¯‘/AIæ ¡å¯¹ï¼‰
     * 
     * å¤„ç†æµç¨‹ï¼š
     * 1. å¯¹æ¯å¼ å›¾ç‰‡é€å¼ æ‰§è¡Œ aiTranslate ä¹‹å‰çš„æ­¥éª¤
     * 2. æ‰¹é‡å‘é€ aiTranslateï¼ˆåˆ©ç”¨ AI çš„å¤šå›¾ä¸Šä¸‹æ–‡èƒ½åŠ›ï¼‰
     * 3. å¯¹æ¯å¼ å›¾ç‰‡é€å¼ æ‰§è¡Œ aiTranslate ä¹‹åçš„æ­¥éª¤
     * 
     * è¿™æ ·è®¾è®¡çš„å¥½å¤„ï¼š
     * - é™¤ aiTranslate å¤–ï¼Œå…¶ä»–æ­¥éª¤éƒ½æ˜¯é€å¼ å¤„ç†ï¼Œä»£ç ç®€å•
     * - æœªæ¥æ·»åŠ æ–°æ­¥éª¤æ›´å®¹æ˜“
     * - aiTranslate ä»ç„¶ä¿æŒæ‰¹é‡å‘é€ï¼Œåˆ©ç”¨ AI çš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›
     */
    async function executeBatchMode(
        tasks: TaskState[],
        stepChain: AtomicStepType[],
        config: PipelineConfig,
        errors: string[]
    ): Promise<{ completed: number; failed: number }> {
        let completed = 0
        let failed = 0

        const batchSize = getBatchSize(config.mode)
        const totalBatches = Math.ceil(tasks.length / batchSize)

        // æ‰¾åˆ° aiTranslate æ­¥éª¤çš„ä½ç½®
        const aiTranslateIdx = stepChain.indexOf('aiTranslate')
        const stepsBeforeAi = aiTranslateIdx >= 0 ? stepChain.slice(0, aiTranslateIdx) : stepChain
        const stepsAfterAi = aiTranslateIdx >= 0 ? stepChain.slice(aiTranslateIdx + 1) : []

        console.log(`ğŸ“¦ æ‰¹æ¬¡å¤„ç†æ¨¡å¼ï¼šå…± ${tasks.length} å¼ å›¾ç‰‡ï¼Œæ¯æ‰¹ ${batchSize} å¼ ï¼Œå…± ${totalBatches} æ‰¹`)
        console.log(`   AIç¿»è¯‘å‰æ­¥éª¤: [${stepsBeforeAi.join(' â†’ ')}]`)
        console.log(`   AIç¿»è¯‘åæ­¥éª¤: [${stepsAfterAi.join(' â†’ ')}]`)

        for (let batchIdx = 0; batchIdx < totalBatches; batchIdx++) {
            // æ£€æŸ¥æ˜¯å¦å–æ¶ˆ
            if (config.scope === 'all' && !imageStore.isBatchTranslationInProgress) {
                console.log(`â¹ï¸ æ‰¹é‡ç¿»è¯‘å·²å–æ¶ˆï¼Œåœæ­¢å¤„ç†`)
                break
            }

            const batchStart = batchIdx * batchSize
            const batchEnd = Math.min(batchStart + batchSize, tasks.length)
            const batchTasks = tasks.slice(batchStart, batchEnd)

            const batchProgress = Math.floor((batchIdx / totalBatches) * 90)
            reporter.setPercentage(batchProgress, `å¤„ç†æ‰¹æ¬¡ ${batchIdx + 1}/${totalBatches}`)
            toast.info(`å¤„ç†æ‰¹æ¬¡ ${batchIdx + 1}/${totalBatches}ï¼ˆå›¾ç‰‡ ${batchStart + 1}-${batchEnd}ï¼‰...`)

            // æ ‡è®°æ‰¹æ¬¡å†…å›¾ç‰‡ä¸ºå¤„ç†ä¸­
            for (const task of batchTasks) {
                imageStore.setTranslationStatus(task.imageIndex, 'processing')
            }

            // è·Ÿè¸ªæ‰¹æ¬¡å†…å¤±è´¥çš„ä»»åŠ¡ç´¢å¼•
            const batchFailedIndices = new Set<number>()

            // ========== é˜¶æ®µ1ï¼šé€å¼ æ‰§è¡Œ aiTranslate ä¹‹å‰çš„æ­¥éª¤ ==========
            for (let i = 0; i < batchTasks.length; i++) {
                const task = batchTasks[i]!

                for (const step of stepsBeforeAi) {
                    if (batchFailedIndices.has(task.imageIndex)) break

                    if (rateLimiter.value) {
                        await rateLimiter.value.acquire()
                    }

                    try {
                        const stepProgress = batchProgress + Math.floor((i / batchTasks.length) * 30)
                        reporter.setPercentage(stepProgress, `å›¾ç‰‡ ${batchStart + i + 1}: ${STEP_LABELS[step]}`)
                        await executeStep(step, task)
                    } catch (err) {
                        const msg = err instanceof Error ? err.message : 'æœªçŸ¥é”™è¯¯'
                        errors.push(`å›¾ç‰‡ ${task.imageIndex + 1}: ${step} - ${msg}`)
                        imageStore.setTranslationStatus(task.imageIndex, 'failed', msg)
                        batchFailedIndices.add(task.imageIndex)
                    }
                }
            }

            // ========== é˜¶æ®µ2ï¼šæ‰¹é‡æ‰§è¡Œ aiTranslate ==========
            if (aiTranslateIdx >= 0) {
                const stepProgress = batchProgress + 40
                reporter.setPercentage(stepProgress, `æ‰¹æ¬¡ ${batchIdx + 1}: ${STEP_LABELS['aiTranslate']}`)

                try {
                    const validTasks = batchTasks.filter(t => !batchFailedIndices.has(t.imageIndex))
                    if (validTasks.length > 0) {
                        await executeAiTranslate(validTasks)
                    }
                } catch (err) {
                    const msg = err instanceof Error ? err.message : 'æœªçŸ¥é”™è¯¯'
                    errors.push(`æ‰¹æ¬¡ ${batchIdx + 1} AIç¿»è¯‘å¤±è´¥: ${msg}`)
                    // AIç¿»è¯‘å¤±è´¥ï¼Œæ ‡è®°æ‰€æœ‰æœªå¤±è´¥çš„ä»»åŠ¡ä¸ºå¤±è´¥
                    for (const task of batchTasks) {
                        if (!batchFailedIndices.has(task.imageIndex)) {
                            imageStore.setTranslationStatus(task.imageIndex, 'failed', msg)
                            batchFailedIndices.add(task.imageIndex)
                        }
                    }
                }
            }

            // ========== é˜¶æ®µ3ï¼šé€å¼ æ‰§è¡Œ aiTranslate ä¹‹åçš„æ­¥éª¤ ==========
            for (let i = 0; i < batchTasks.length; i++) {
                const task = batchTasks[i]!

                if (batchFailedIndices.has(task.imageIndex)) continue

                for (const step of stepsAfterAi) {
                    if (batchFailedIndices.has(task.imageIndex)) break

                    if (rateLimiter.value) {
                        await rateLimiter.value.acquire()
                    }

                    try {
                        const stepProgress = batchProgress + 50 + Math.floor((i / batchTasks.length) * 40)
                        reporter.setPercentage(stepProgress, `å›¾ç‰‡ ${batchStart + i + 1}: ${STEP_LABELS[step]}`)
                        await executeStep(step, task)
                    } catch (err) {
                        const msg = err instanceof Error ? err.message : 'æœªçŸ¥é”™è¯¯'
                        errors.push(`å›¾ç‰‡ ${task.imageIndex + 1}: ${step} - ${msg}`)
                        imageStore.setTranslationStatus(task.imageIndex, 'failed', msg)
                        batchFailedIndices.add(task.imageIndex)
                    }
                }

                // è¿™å¼ å›¾ç‰‡å¤„ç†å®Œæˆï¼ˆaiTranslate åçš„æ­¥éª¤éƒ½å®Œæˆäº†ï¼‰ï¼Œç«‹å³æ›´æ–° store
                if (!batchFailedIndices.has(task.imageIndex)) {
                    updateImageStore(task)
                    completed++
                    console.log(`âœ… å›¾ç‰‡ ${batchStart + i + 1} å¤„ç†å®Œæˆ`)
                }
            }

            // ç»Ÿè®¡å¤±è´¥æ•°é‡
            failed += batchFailedIndices.size

            console.log(`âœ… æ‰¹æ¬¡ ${batchIdx + 1}/${totalBatches} å¤„ç†å®Œæˆ`)
        }

        return { completed, failed }
    }

    async function execute(config: PipelineConfig): Promise<PipelineResult> {
        if (!validateConfig(config)) {
            return { success: false, completed: 0, failed: 0, errors: ['é…ç½®éªŒè¯å¤±è´¥'] }
        }

        const images = imageStore.images
        if (images.length === 0) {
            toast.error('è¯·å…ˆä¸Šä¼ å›¾ç‰‡')
            return { success: false, completed: 0, failed: 0, errors: ['æ²¡æœ‰å›¾ç‰‡'] }
        }

        currentMode = config.mode
        const usePerImageMode = shouldUsePerImageMode(config.mode)

        isExecuting.value = true
        if (config.scope === 'all' || config.scope === 'failed') {
            imageStore.setBatchTranslationInProgress(true)
        }
        initRateLimiter()
        saveCurrentStyles()

        const imagesToProcess = getImagesToProcess(config)
        const errors: string[] = []

        // åˆ¤æ–­æ˜¯å¦å¯ç”¨è‡ªåŠ¨ä¿å­˜ï¼ˆä¹¦æ¶æ¨¡å¼ + è®¾ç½®å¼€å¯ï¼‰
        const enableAutoSave = shouldEnableAutoSave()

        // åŠ¨æ€ç”Ÿæˆæ­¥éª¤é“¾ï¼šå¦‚æœå¯ç”¨è‡ªåŠ¨ä¿å­˜ï¼Œè¿½åŠ  save æ­¥éª¤
        const stepChain = [...STEP_CHAIN_CONFIGS[config.mode]]
        if (enableAutoSave) {
            stepChain.push('save')
        }

        console.log(`ğŸš€ é¡ºåºç®¡çº¿å¯åŠ¨`)
        console.log(`   æ¨¡å¼: ${config.mode}`)
        console.log(`   å¤„ç†æ–¹å¼: ${usePerImageMode ? 'é€å¼ å¤„ç†' : 'æ‰¹æ¬¡å¤„ç†'}`)
        console.log(`   æ­¥éª¤é“¾: [${stepChain.join(' â†’ ')}]`)
        console.log(`   è‡ªåŠ¨ä¿å­˜: ${enableAutoSave ? 'å¯ç”¨' : 'ç¦ç”¨'}`)

        // åˆ›å»ºä»»åŠ¡çŠ¶æ€
        const tasks: TaskState[] = imagesToProcess.map(({ image, index }) => {
            const task: TaskState = {
                imageIndex: index,
                image,
                bubbleCoords: [],
                bubbleAngles: [],
                bubblePolygons: [],
                autoDirections: [],
                textlinesPerBubble: [],
                originalTexts: [],
                colors: [],
                translatedTexts: [],
                textboxTexts: []
            }

            // æ ¡å¯¹æ¨¡å¼éœ€è¦ä»å·²æœ‰æ•°æ®åˆå§‹åŒ–
            if (config.mode === 'proofread' && image.bubbleStates && image.bubbleStates.length > 0) {
                task.bubbleCoords = image.bubbleStates.map(s => s.coords)
                task.bubbleAngles = image.bubbleStates.map(s => s.rotationAngle || 0)
                task.autoDirections = image.bubbleStates.map(s => s.autoTextDirection || s.textDirection || 'vertical')
                task.originalTexts = image.bubbleStates.map(s => s.originalText || '')
                task.translatedTexts = image.bubbleStates.map(s => s.translatedText || '')
                task.textboxTexts = image.bubbleStates.map(s => s.textboxText || '')
                task.colors = image.bubbleStates.map(s => ({
                    textColor: s.textColor || '',
                    bgColor: s.fillColor || '',
                    autoFgColor: s.autoFgColor || null,
                    autoBgColor: s.autoBgColor || null
                }))
                // ä½¿ç”¨å·²æœ‰çš„å¹²å‡€èƒŒæ™¯å›¾
                if (image.cleanImageData) {
                    task.cleanImage = image.cleanImageData
                }
            }

            return task
        })

        try {
            reporter.init(imagesToProcess.length, `${config.mode} æ¨¡å¼å¯åŠ¨...`)

            // å¦‚æœå¯ç”¨è‡ªåŠ¨ä¿å­˜ï¼Œå…ˆæ‰§è¡Œé¢„ä¿å­˜ï¼ˆä¿å­˜æ‰€æœ‰åŸå§‹å›¾ç‰‡ï¼‰
            if (enableAutoSave) {
                reporter.setPercentage(0, 'é¢„ä¿å­˜åŸå§‹å›¾ç‰‡...')
                const preSaveSuccess = await preSaveOriginalImages({
                    onStart: (total) => {
                        reporter.setPercentage(0, `é¢„ä¿å­˜åŸå§‹å›¾ç‰‡ 0/${total}...`)
                    },
                    onProgress: (current, total) => {
                        const percent = Math.round((current / total) * 10) // é¢„ä¿å­˜å  0-10%
                        reporter.setPercentage(percent, `é¢„ä¿å­˜åŸå§‹å›¾ç‰‡ ${current}/${total}...`)
                    },
                    onComplete: () => {
                        reporter.setPercentage(10, 'é¢„ä¿å­˜å®Œæˆï¼Œå¼€å§‹ç¿»è¯‘...')
                    },
                    onError: (error) => {
                        reporter.setPercentage(0, `é¢„ä¿å­˜å¤±è´¥: ${error}`)
                    }
                })
                if (!preSaveSuccess) {
                    // é¢„ä¿å­˜å¤±è´¥ï¼Œæç¤ºç”¨æˆ·ä½†ä¸é˜»æ­¢ç¿»è¯‘
                    toast.warning('é¢„ä¿å­˜å¤±è´¥ï¼Œç¿»è¯‘å®Œæˆåè¯·æ‰‹åŠ¨ä¿å­˜')
                }
            }

            let result: { completed: number; failed: number }

            if (usePerImageMode) {
                // é€å¼ å¤„ç†æ¨¡å¼
                result = await executePerImageMode(tasks, stepChain, config, errors)
            } else {
                // æ‰¹æ¬¡å¤„ç†æ¨¡å¼
                result = await executeBatchMode(tasks, stepChain, config, errors)
            }

            reporter.setPercentage(100, 'å®Œæˆï¼')

            const modeLabels: Record<TranslationMode, string> = {
                standard: 'ç¿»è¯‘',
                hq: 'é«˜è´¨é‡ç¿»è¯‘',
                proofread: 'AIæ ¡å¯¹',
                removeText: 'æ¶ˆé™¤æ–‡å­—'
            }
            toast.success(`${modeLabels[config.mode]}å®Œæˆï¼`)

            return {
                success: result.failed === 0,
                completed: result.completed,
                failed: result.failed,
                errors: errors.length > 0 ? errors : undefined
            }

        } catch (error) {
            const errorMessage = error instanceof Error ? error.message : 'æ‰§è¡Œå¤±è´¥'
            toast.error(errorMessage)
            errors.push(errorMessage)
            return {
                success: false,
                completed: 0,
                failed: imagesToProcess.length,
                errors
            }

        } finally {
            isExecuting.value = false
            imageStore.setBatchTranslationInProgress(false)

            // å¦‚æœå¯ç”¨äº†è‡ªåŠ¨ä¿å­˜ï¼Œå®Œæˆä¿å­˜ä¼šè¯
            if (enableAutoSave) {
                await finalizeSave()
            }

            const currentIndex = imageStore.currentImageIndex
            const currentImage = imageStore.images[currentIndex]
            if (currentImage?.bubbleStates && currentImage.bubbleStates.length > 0) {
                bubbleStore.setBubbles(currentImage.bubbleStates)
            }

            setTimeout(() => reporter.finish(), 1000)
        }
    }

    function cancel(): void {
        if (imageStore.isBatchTranslationInProgress) {
            imageStore.setBatchTranslationInProgress(false)
            // é‡ç½®è‡ªåŠ¨ä¿å­˜çŠ¶æ€
            resetSaveState()
            toast.info('æ“ä½œå·²å–æ¶ˆ')
        }
    }

    return {
        progress,
        isExecuting,
        isTranslating,
        progressPercent,
        execute,
        cancel,
        STEP_CHAIN_CONFIGS
    }
}
